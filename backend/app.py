from flask import Flask, request, jsonify, send_file, Response
from flask_cors import CORS
import yt_dlp
import os
import json
import uuid
import threading
import time
from datetime import datetime
import tempfile
import shutil
from urllib.parse import urlparse, parse_qs
import re
import random
import requests

app = Flask(__name__)
CORS(app, origins=["*"], allow_headers=["Content-Type"], methods=["GET", "POST", "OPTIONS"])

# Store download progress
download_progress = {}

# Enhanced user agents pool
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1',
    'Mozilla/5.0 (iPad; CPU OS 17_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1',
    'Mozilla/5.0 (Linux; Android 13; SM-G991B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Mobile Safari/537.36',
]

class DownloadProgress:
    def __init__(self, download_id):
        self.download_id = download_id
        self.status = 'preparing'
        self.progress = 0
        self.speed = '0 B/s'
        self.eta = 'Unknown'
        self.size = '0 B'
        self.title = ''
        self.thumbnail = ''
        self.error = None
        self.file_path = None
        self.filename = ''

    def update(self, d):
        if d['status'] == 'downloading':
            self.status = 'downloading'
            self.progress = d.get('_percent_str', '0%').replace('%', '')
            self.speed = d.get('_speed_str', '0 B/s')
            self.eta = d.get('_eta_str', 'Unknown')
            self.size = d.get('_total_bytes_str', '0 B')
        elif d['status'] == 'finished':
            self.status = 'processing'
            self.progress = 100

def get_browser_cookies():
    """Extract cookies from browser"""
    try:
        import browser_cookie3
        
        # Try different browsers in order of preference
        browsers = [
            ('chrome', browser_cookie3.chrome),
            ('firefox', browser_cookie3.firefox),
            ('edge', browser_cookie3.edge),
            ('safari', browser_cookie3.safari)
        ]
        
        for browser_name, browser_func in browsers:
            try:
                print(f"Trying to extract cookies from {browser_name}...")
                cookies = list(browser_func(domain_name='youtube.com'))
                if cookies:
                    print(f"Successfully extracted {len(cookies)} cookies from {browser_name}")
                    return cookies, browser_name
            except Exception as e:
                print(f"Failed to extract cookies from {browser_name}: {str(e)}")
                continue
                
    except ImportError:
        print("browser_cookie3 not installed. Install with: pip install browser_cookie3")
        
    return None, None

def save_cookies_to_file(cookies, filename='cookies.txt'):
    """Save cookies to Netscape format file"""
    try:
        with open(filename, 'w') as f:
            f.write('# Netscape HTTP Cookie File\n')
            f.write('# Generated by yt-dlp YouTube Downloader\n\n')
            
            for cookie in cookies:
                # Format: domain, domain_specified, path, secure, expires, name, value
                domain_specified = 'TRUE' if cookie.domain.startswith('.') else 'FALSE'
                secure = 'TRUE' if cookie.secure else 'FALSE'
                expires = str(int(cookie.expires)) if cookie.expires else '0'
                
                f.write(f"{cookie.domain}\t{domain_specified}\t{cookie.path}\t{secure}\t{expires}\t{cookie.name}\t{cookie.value}\n")
        
        return True
    except Exception as e:
        print(f"Error saving cookies: {str(e)}")
        return False

def get_enhanced_ydl_opts():
    """Get enhanced yt-dlp options with proper authentication"""
    
    # Base configuration
    opts = {
        'quiet': True,
        'no_warnings': True,
        'no_color': True,
        
        # Browser simulation
        'user_agent': random.choice(USER_AGENTS),
        'referer': 'https://www.youtube.com/',
        
        # Enhanced headers to mimic real browser
        'http_headers': {
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache',
            'DNT': '1',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Sec-Ch-Ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
            'Sec-Ch-Ua-Mobile': '?0',
            'Sec-Ch-Ua-Platform': '"Windows"',
            'Origin': 'https://www.youtube.com',
            'Connection': 'keep-alive'
        },
        
        # Network and retry settings
        'socket_timeout': 60,
        'retries': 15,
        'fragment_retries': 15,
        'skip_unavailable_fragments': True,
        'keep_fragments': False,
        'concurrent_fragment_downloads': 1,
        'http_chunk_size': 10485760,  # 10MB chunks max for YouTube
        
        # Rate limiting
        'sleep_interval': 3,
        'max_sleep_interval': 8,
        'sleep_interval_requests': 2,
        
        # Enhanced YouTube extractor args
        'extractor_args': {
            'youtube': {
                'player_client': ['ios', 'android', 'tv_embed'],
                'player_skip': ['webpage', 'configs'],
                'skip': ['hls', 'dash', 'translated_subs'],
                'innertube_host': 'youtubei.googleapis.com',
                'comment_sort': 'top',
                'max_comments': 0,
                'max_comment_depth': 0
            }
        },
        
        # Format preferences
        'format_sort': [
            'res:1080',
            'fps:30', 
            'codec:h264',
            'size',
            'br',
            'asr',
            'proto'
        ]
    }
    
    # Add cookies if available
    if os.path.exists('cookies.txt'):
        opts['cookiefile'] = 'cookies.txt'
        print("Using cookies.txt for authentication")
    
    return opts

def extract_video_id(url):
    """Extract video ID from YouTube URL"""
    patterns = [
        r'(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/)([^&\n?#]+)',
        r'youtube\.com\/shorts\/([^&\n?#]+)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    
    parsed = urlparse(url)
    if parsed.hostname in ('www.youtube.com', 'youtube.com', 'm.youtube.com'):
        query = parse_qs(parsed.query)
        if 'v' in query:
            return query['v'][0]
    
    return None

def try_alternative_extraction(url):
    """Try alternative methods to get basic video info"""
    try:
        video_id = extract_video_id(url)
        if not video_id:
            return None
            
        # Try YouTube's oembed API
        oembed_url = f"https://www.youtube.com/oembed?url=https://www.youtube.com/watch?v={video_id}&format=json"
        
        headers = {
            'User-Agent': random.choice(USER_AGENTS),
            'Referer': 'https://www.youtube.com/',
            'Accept': 'application/json'
        }
        
        response = requests.get(oembed_url, headers=headers, timeout=15)
        if response.status_code == 200:
            data = response.json()
            return {
                'title': data.get('title', 'Unknown'),
                'uploader': data.get('author_name', 'Unknown'),
                'thumbnail': data.get('thumbnail_url', ''),
                'duration': 0,
                'view_count': 0,
                'video_id': video_id,
                'webpage_url': url,
                'formats_available': False,
                'fallback_method': 'oembed',
                'warning': 'Limited info available - full extraction blocked'
            }
    except Exception as e:
        print(f"Alternative extraction failed: {str(e)}")
        
    return None

@app.route('/', methods=['GET'])
def root():
    return jsonify({
        'service': 'Enhanced YouTube Downloader API',
        'version': '3.0.0',
        'status': 'running',
        'features': [
            'Cookie-based authentication',
            'Enhanced bot detection bypass',
            'Multiple extraction strategies',
            'Automatic browser cookie extraction'
        ],
        'endpoints': {
            'health': '/api/health',
            'info': '/api/info',
            'download': '/api/download',
            'formats': '/api/formats',
            'setup_cookies': '/api/setup-cookies',
            'manual_cookies': '/api/manual-cookies',
            'cookie_status': '/api/cookie-status',
            'instructions': '/api/cookie-instructions'
        }
    })

@app.route('/api/health', methods=['GET'])
def health_check():
    cookie_status = 'available' if os.path.exists('cookies.txt') else 'missing'
    
    return jsonify({
        'status': 'ok',
        'timestamp': datetime.now().isoformat(),
        'service': 'Enhanced YouTube Downloader API',
        'yt_dlp_version': yt_dlp.version.__version__,
        'cookie_status': cookie_status
    })

@app.route('/api/setup-cookies', methods=['POST'])
def setup_cookies():
    """Automatically extract cookies from browser"""
    try:
        cookies, browser_name = get_browser_cookies()
        
        if not cookies:
            return jsonify({
                'error': 'No cookies found',
                'message': 'Could not extract cookies from any browser',
                'solutions': [
                    'Make sure you have visited YouTube in your browser recently',
                    'Try the manual cookie method using /api/manual-cookies',
                    'Install browser_cookie3: pip install browser_cookie3'
                ]
            }), 404
        
        # Save cookies to file
        if save_cookies_to_file(cookies):
            return jsonify({
                'status': 'success',
                'message': f'Successfully extracted {len(cookies)} cookies from {browser_name}',
                'browser': browser_name,
                'cookie_count': len(cookies),
                'next_step': 'You can now use the API normally'
            })
        else:
            return jsonify({
                'error': 'Failed to save cookies',
                'message': 'Cookies were extracted but could not be saved to file'
            }), 500
            
    except Exception as e:
        return jsonify({
            'error': 'Cookie extraction failed',
            'details': str(e),
            'solution': 'Try manual cookie method or check browser installation'
        }), 500

@app.route('/api/manual-cookies', methods=['POST'])
def manual_cookies():
    """Accept manually exported cookies"""
    try:
        data = request.get_json()
        cookies_content = data.get('cookies')
        
        if not cookies_content:
            return jsonify({
                'error': 'No cookies provided',
                'required_format': 'Netscape HTTP Cookie File format'
            }), 400
        
        # Validate and fix cookie format
        if not cookies_content.strip().startswith('# Netscape HTTP Cookie File'):
            cookies_content = '# Netscape HTTP Cookie File\n# Generated manually\n\n' + cookies_content
        
        # Save cookies
        with open('cookies.txt', 'w') as f:
            f.write(cookies_content)
        
        # Validate by counting non-comment lines
        cookie_lines = [line for line in cookies_content.split('\n') 
                       if line.strip() and not line.startswith('#')]
        
        return jsonify({
            'status': 'success',
            'message': f'Successfully saved {len(cookie_lines)} cookie entries',
            'next_step': 'You can now use the API normally'
        })
        
    except Exception as e:
        return jsonify({
            'error': 'Failed to save manual cookies',
            'details': str(e)
        }), 500

@app.route('/api/cookie-status', methods=['GET'])
def cookie_status():
    """Check current cookie status"""
    if not os.path.exists('cookies.txt'):
        return jsonify({
            'status': 'missing',
            'message': 'No cookies file found',
            'action_needed': 'Set up cookies using /api/setup-cookies or /api/manual-cookies'
        })
    
    try:
        # Check cookie file age and content
        stat = os.stat('cookies.txt')
        age_hours = (time.time() - stat.st_mtime) / 3600
        
        with open('cookies.txt', 'r') as f:
            content = f.read()
            cookie_count = len([line for line in content.split('\n') 
                              if line.strip() and not line.startswith('#')])
        
        status = 'fresh' if age_hours < 24 else 'old' if age_hours < 168 else 'stale'
        
        return jsonify({
            'status': 'available',
            'cookie_count': cookie_count,
            'age_hours': round(age_hours, 1),
            'freshness': status,
            'recommendation': 'Refresh cookies if older than 24 hours' if age_hours > 24 else 'Cookies are fresh'
        })
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'error': str(e)
        })

@app.route('/api/cookie-instructions', methods=['GET'])
def cookie_instructions():
    """Provide detailed cookie setup instructions"""
    return jsonify({
        'title': 'Cookie Setup Instructions',
        'automatic_method': {
            'description': 'Let the API extract cookies automatically from your browser',
            'endpoint': 'POST /api/setup-cookies',
            'requirements': [
                'Have visited YouTube in your browser recently',
                'browser_cookie3 package installed',
                'Supported browsers: Chrome, Firefox, Edge, Safari'
            ],
            'steps': [
                '1. Visit youtube.com in your browser',
                '2. Solve any CAPTCHA if prompted',
                '3. Make a POST request to /api/setup-cookies',
                '4. API will automatically extract and save cookies'
            ]
        },
        'manual_method': {
            'description': 'Export cookies manually using browser extension',
            'endpoint': 'POST /api/manual-cookies',
            'recommended_extensions': [
                'Get cookies.txt LOCALLY (Chrome)',
                'cookies.txt (Firefox)'
            ],
            'steps': [
                '1. Install a cookie export extension',
                '2. Visit youtube.com and solve any CAPTCHA',
                '3. Export cookies for youtube.com domain',
                '4. POST the cookie content to /api/manual-cookies'
            ]
        },
        'troubleshooting': {
            'common_issues': [
                'Cookies too old (refresh every 24 hours)',
                'Wrong cookie format (must be Netscape format)',
                'Different IP address between browser and API',
                'Browser not supported for automatic extraction'
            ],
            'solutions': [
                'Use fresh browser session before extracting cookies',
                'Ensure cookie file starts with "# Netscape HTTP Cookie File"',
                'Use same network/IP for browser and API calls',
                'Try manual method if automatic fails'
            ]
        },
        'security_note': 'Cookies contain sensitive authentication data. Keep them secure and refresh regularly.'
    })

@app.route('/api/info', methods=['POST'])
def get_video_info():
    try:
        data = request.get_json()
        url = data.get('url')
        
        if not url:
            return jsonify({'error': 'URL is required'}), 400
        
        # Check for cookies
        if not os.path.exists('cookies.txt'):
            return jsonify({
                'error': 'Authentication required',
                'message': 'YouTube requires authentication. Please set up cookies first.',
                'instructions': {
                    'automatic': 'POST to /api/setup-cookies',
                    'manual': 'POST cookies to /api/manual-cookies',
                    'help': 'GET /api/cookie-instructions for detailed help'
                }
            }), 401
        
        # Random delay to avoid detection
        time.sleep(random.uniform(1, 3))
        
        # Try enhanced extraction strategies
        strategies = [
            # Strategy 1: iOS client with fresh headers
            {
                'extractor_args': {
                    'youtube': {
                        'player_client': ['ios'],
                        'player_skip': ['webpage', 'configs'],
                        'skip': ['hls', 'dash', 'translated_subs']
                    }
                },
                'http_headers': {
                    'User-Agent': 'com.google.ios.youtube/19.29.1 (iPhone16,2; U; CPU iOS 17_5_1 like Mac OS X;)',
                    'X-YouTube-Client-Name': '5',
                    'X-YouTube-Client-Version': '19.29.1'
                }
            },
            # Strategy 2: Android TV client
            {
                'extractor_args': {
                    'youtube': {
                        'player_client': ['android_tv'],
                        'player_skip': ['configs'],
                        'skip': ['translated_subs']
                    }
                }
            },
            # Strategy 3: TV embed with bypass
            {
                'extractor_args': {
                    'youtube': {
                        'player_client': ['tv_embed'],
                        'player_skip': ['webpage'],
                        'bypass_age_gate': True
                    }
                }
            }
        ]
        
        last_error = None
        
        for i, strategy in enumerate(strategies):
            try:
                print(f"Trying extraction strategy {i+1}/{len(strategies)}")
                
                ydl_opts = get_enhanced_ydl_opts()
                ydl_opts.update({
                    'extract_flat': False,
                    'skip_download': True,
                    'getcomments': False,
                    'writesubtitles': False,
                    'writeautomaticsub': False,
                    'ignoreerrors': False
                })
                ydl_opts.update(strategy)
                
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    info = ydl.extract_info(url, download=False)
                    
                    if not info:
                        continue
                    
                    # Extract available formats
                    formats = []
                    audio_formats = []
                    
                    for f in info.get('formats', []):
                        if f.get('format_note') == 'storyboard':
                            continue
                            
                        # Video formats
                        if f.get('vcodec') != 'none' and f.get('acodec') == 'none':
                            height = f.get('height', 0)
                            if height >= 240:
                                formats.append({
                                    'format_id': f['format_id'],
                                    'resolution': f"{height}p",
                                    'height': height,
                                    'fps': f.get('fps', 30),
                                    'filesize': f.get('filesize', 0),
                                    'filesize_approx': f.get('filesize_approx', 0),
                                    'vcodec': f.get('vcodec', 'unknown'),
                                    'ext': f.get('ext', 'mp4'),
                                    'format_note': f.get('format_note', '')
                                })
                        # Audio formats
                        elif f.get('acodec') != 'none' and f.get('vcodec') == 'none':
                            audio_formats.append({
                                'format_id': f['format_id'],
                                'abr': f.get('abr', 0),
                                'asr': f.get('asr', 44100),
                                'acodec': f.get('acodec', 'unknown'),
                                'filesize': f.get('filesize', 0),
                                'filesize_approx': f.get('filesize_approx', 0),
                                'ext': f.get('ext', 'webm'),
                                'format_note': f.get('format_note', '')
                            })
                    
                    # Sort formats
                    formats.sort(key=lambda x: x['height'], reverse=True)
                    audio_formats.sort(key=lambda x: x['abr'], reverse=True)
                    
                    best_video = formats[0] if formats else None
                    best_audio = audio_formats[0] if audio_formats else None
                    
                    return jsonify({
                        'title': info.get('title', 'Unknown'),
                        'thumbnail': info.get('thumbnail', ''),
                        'duration': info.get('duration', 0),
                        'uploader': info.get('uploader', 'Unknown'),
                        'view_count': info.get('view_count', 0),
                        'upload_date': info.get('upload_date', ''),
                        'description': info.get('description', '')[:500],
                        'video_formats': formats[:15],
                        'audio_formats': audio_formats[:8],
                        'best_video': best_video,
                        'best_audio': best_audio,
                        'video_id': extract_video_id(url),
                        'webpage_url': info.get('webpage_url', url),
                        'strategy_used': i + 1,
                        'formats_available': len(formats) > 0,
                        'status': 'success'
                    })
                    
            except Exception as e:
                last_error = str(e)
                print(f"Strategy {i+1} failed: {last_error}")
                
                # Check for specific authentication errors
                if any(phrase in last_error.lower() for phrase in ['sign in', 'bot', 'captcha', 'forbidden']):
                    return jsonify({
                        'error': 'YouTube authentication challenge',
                        'message': 'YouTube is requesting additional verification',
                        'solutions': [
                            'Refresh your browser cookies',
                            'Visit YouTube and solve any CAPTCHA',
                            'Update cookies using /api/setup-cookies',
                            'Try again in a few minutes'
                        ],
                        'technical_error': last_error
                    }), 403
                
                if i < len(strategies) - 1:
                    time.sleep(random.uniform(2, 5))
                    continue
                
        # Try alternative extraction as fallback
        alt_info = try_alternative_extraction(url)
        if alt_info:
            alt_info['warning'] = 'Full extraction failed, showing limited info from alternative source'
            alt_info['error_details'] = last_error
            return jsonify(alt_info)
        
        # All methods failed
        return jsonify({
            'error': 'Complete extraction failure',
            'message': 'All extraction methods failed',
            'last_error': str(last_error),
            'suggestions': [
                'Update cookies using /api/setup-cookies',
                'Check if video is available in your region', 
                'Try again later as YouTube may have temporary restrictions',
                'Update yt-dlp: pip install --upgrade yt-dlp'
            ]
        }), 503
            
    except Exception as e:
        return jsonify({
            'error': 'Server error during extraction',
            'details': str(e)
        }), 500

@app.route('/api/download', methods=['POST'])
def download_video():
    try:
        data = request.get_json()
        url = data.get('url')
        quality = data.get('quality', 'best')
        audio_quality = data.get('audio_quality', 'best')
        
        if not url:
            return jsonify({'error': 'URL is required'}), 400
        
        if not os.path.exists('cookies.txt'):
            return jsonify({
                'error': 'Authentication required',
                'message': 'Please set up cookies first using /api/setup-cookies'
            }), 401
        
        download_id = str(uuid.uuid4())
        progress_tracker = DownloadProgress(download_id)
        download_progress[download_id] = progress_tracker
        
        thread = threading.Thread(
            target=perform_enhanced_download,
            args=(url, quality, audio_quality, progress_tracker)
        )
        thread.daemon = True
        thread.start()
        
        return jsonify({
            'download_id': download_id,
            'status': 'started'
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

def perform_enhanced_download(url, quality, audio_quality, progress_tracker):
    """Enhanced download with authentication and multiple strategies"""
    temp_dir = tempfile.mkdtemp()
    
    try:
        # Random delay
        time.sleep(random.uniform(2, 5))
        
        def progress_hook(d):
            progress_tracker.update(d)
        
        # Format selection
        format_map = {
            'best': 'best[ext=mp4]/best',
            '8k': 'best[height<=4320][ext=mp4]/best[height<=4320]',
            '4k': 'best[height<=2160][ext=mp4]/best[height<=2160]',
            '2k': 'best[height<=1440][ext=mp4]/best[height<=1440]',
            '1080p': 'best[height<=1080][ext=mp4]/best[height<=1080]',
            '720p': 'best[height<=720][ext=mp4]/best[height<=720]',
            '480p': 'best[height<=480][ext=mp4]/best[height<=480]',
            '360p': 'best[height<=360][ext=mp4]/best[height<=360]',
            '240p': 'best[height<=240][ext=mp4]/best[height<=240]'
        }
        
        format_string = format_map.get(quality, 'best[ext=mp4]/best')
        output_template = os.path.join(temp_dir, '%(title).200B.%(ext)s')
        
        # Download strategies
        strategies = [
            {
                'extractor_args': {
                    'youtube': {
                        'player_client': ['ios'],
                        'player_skip': ['webpage', 'configs'],
                        'skip': ['hls', 'dash']
                    }
                }
            },
            {
                'extractor_args': {
                    'youtube': {
                        'player_client': ['android_tv'],
                        'player_skip': ['configs']
                    }
                }
            },
            {
                'extractor_args': {
                    'youtube': {
                        'player_client': ['tv_embed'],
                        'bypass_age_gate': True
                    }
                }
            }
        ]
        
        for i, strategy in enumerate(strategies):
            try:
                print(f"Download strategy {i+1}/{len(strategies)}")
                
                ydl_opts = get_enhanced_ydl_opts()
                ydl_opts.update({
                    'format': format_string,
                    'outtmpl': output_template,
                    'progress_hooks': [progress_hook],
                    'merge_output_format': 'mp4',
                    'prefer_ffmpeg': True,
                    'keepvideo': False,
                    'writeinfojson': False,
                    'writethumbnail': False,
                    'writesubtitles': False,
                    'writeautomaticsub': False,
                    'getcomments': False,
                    'ignoreerrors': False
                })
                ydl_opts.update(strategy)
                
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    info = ydl.extract_info(url, download=True)
                    progress_tracker.title = info.get('title', 'Unknown')
                    progress_tracker.thumbnail = info.get('thumbnail', '')
                    
                    # Find downloaded file
                    for file in os.listdir(temp_dir):
                        if file.endswith(('.mp4', '.webm', '.mkv', '.mov', '.avi', '.m4a', '.mp3')):
                            progress_tracker.file_path = os.path.join(temp_dir, file)
                            progress_tracker.filename = file
                            break
                    
                    if progress_tracker.file_path:
                        progress_tracker.status = 'completed'
                        return
                        
            except Exception as e:
                print(f"Download strategy {i+1} failed: {str(e)}")
                if i < len(strategies) - 1:
                    time.sleep(random.uniform(2, 5))
                    continue
                    
        progress_tracker.error = 'All download strategies failed'
        progress_tracker.status = 'error'
                    
    except Exception as e:
        progress_tracker.status = 'error'
        progress_tracker.error = str(e)
    finally:
        if progress_tracker.status == 'error' and os.path.exists(temp_dir):
            try:
                shutil.rmtree(temp_dir)
            except:
                pass

@app.route('/api/progress/<download_id>', methods=['GET'])
def get_progress(download_id):
    if download_id not in download_progress:
        return jsonify({'error': 'Download not found'}), 404
    
    progress = download_progress[download_id]
    
    return jsonify({
        'status': progress.status,
        'progress': progress.progress,
        'speed': progress.speed,
        'eta': progress.eta,
        'size': progress.size,
        'title': progress.title,
        'thumbnail': progress.thumbnail,
        'error': progress.error,
        'filename': progress.filename
    })

@app.route('/api/download/<download_id>/file', methods=['GET'])
def download_file(download_id):
    if download_id not in download_progress:
        return jsonify({'error': 'Download not found'}), 404
    
    progress = download_progress[download_id]
    
    if progress.status != 'completed' or not progress.file_path:
        return jsonify({'error': 'Download not completed'}), 400
    
    try:
        def generate():
            with open(progress.file_path, 'rb') as f:
                while True:
                    data = f.read(4096)
                    if not data:
                        break
                    yield data
            
            # Cleanup
            temp_dir = os.path.dirname(progress.file_path)
            if os.path.exists(temp_dir) and temp_dir.startswith(tempfile.gettempdir()):
                try:
                    shutil.rmtree(temp_dir)
                except:
                    pass
            
            if download_id in download_progress:
                del download_progress[download_id]
        
        response = Response(generate(), mimetype='video/mp4')
        response.headers['Content-Disposition'] = f'attachment; filename="{progress.filename}"'
        return response
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/formats', methods=['GET'])
def get_supported_formats():
    return jsonify({
        'video_qualities': [
            {'id': 'best', 'label': 'Best Available', 'description': 'Highest quality available'},
            {'id': '8k', 'label': '8K (4320p)', 'description': 'Ultra HD 8K'},
            {'id': '4k', 'label': '4K (2160p)', 'description': 'Ultra HD 4K'},
            {'id': '2k', 'label': '2K (1440p)', 'description': 'Quad HD'},
            {'id': '1080p', 'label': '1080p', 'description': 'Full HD'},
            {'id': '720p', 'label': '720p', 'description': 'HD'},
            {'id': '480p', 'label': '480p', 'description': 'SD'},
            {'id': '360p', 'label': '360p', 'description': 'Low'},
            {'id': '240p', 'label': '240p', 'description': 'Very Low'},
        ],
        'note': 'Enhanced with cookie-based authentication and bot detection bypass'
    })

@app.route('/api/test', methods=['GET'])
def test_endpoint():
    try:
        cookie_status = 'available' if os.path.exists('cookies.txt') else 'missing'
        
        return jsonify({
            'status': 'success',
            'message': 'Enhanced API is running',
            'yt_dlp_version': yt_dlp.version.__version__,
            'cookie_status': cookie_status,
            'timestamp': datetime.now().isoformat(),
            'features': [
                'Automatic cookie extraction',
                'Enhanced bot detection bypass',
                'Multiple extraction strategies',
                'Comprehensive error handling'
            ]
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'error': str(e)
        }), 500

@app.errorhandler(404)
def not_found(e):
    return jsonify({
        'error': 'Endpoint not found',
        'available_endpoints': [
            '/',
            '/api/health',
            '/api/info',
            '/api/download',
            '/api/setup-cookies',
            '/api/manual-cookies',
            '/api/cookie-status',
            '/api/cookie-instructions'
        ]
    }), 404

@app.errorhandler(500)
def server_error(e):
    return jsonify({'error': 'Internal server error'}), 500

if __name__ == '__main__':
    print("Starting Enhanced YouTube Downloader API...")
    print("Features: Cookie authentication, Bot detection bypass, Multiple strategies")
    
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)